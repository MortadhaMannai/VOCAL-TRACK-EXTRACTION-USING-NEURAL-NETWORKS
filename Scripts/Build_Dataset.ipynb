{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "import time\n",
    "from IPython.display import Audio\n",
    "from config import PARAS\n",
    "from mel_dealer import mel_converter\n",
    "\n",
    "\n",
    "\n",
    "MIX_PATH = '../DSD100/Mixtures'\n",
    "SRC_PATH = '../DSD100/Sources'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get File Paths\n",
    "\n",
    "- Path Dictionary\n",
    "    - Music File Index\n",
    "        - Track 1 -> path\n",
    "        - Track 2 -> path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_file_paths = dict()\n",
    "test_file_paths = dict()\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(MIX_PATH):\n",
    "    if not dirnames:\n",
    "        if 'Test' in dirpath:\n",
    "            file_name = dirpath.split('Test/')[-1].split('-')[0].strip()\n",
    "            test_file_paths[file_name] = dict()\n",
    "            test_file_paths[file_name]['mix'] = dirpath + '/' + filenames[0]\n",
    "        elif 'Dev' in dirpath:\n",
    "            file_name = dirpath.split('Dev/')[-1].split('-')[0].strip()\n",
    "            dev_file_paths[file_name] = dict()\n",
    "            dev_file_paths[file_name]['mix'] = dirpath + '/' + filenames[0]\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(SRC_PATH):\n",
    "    if not dirnames:\n",
    "        if 'Test' in dirpath:\n",
    "            file_name = dirpath.split('Test/')[-1].split('-')[0].strip()\n",
    "            for trackname in filenames:\n",
    "                track = trackname.split('.wav')[0]\n",
    "                test_file_paths[file_name][track] = dirpath + '/' + trackname\n",
    "        elif 'Dev' in dirpath:\n",
    "            file_name = dirpath.split('Dev/')[-1].split('-')[0].strip()\n",
    "            for trackname in filenames:\n",
    "                track = trackname.split('.wav')[0]\n",
    "                dev_file_paths[file_name][track] = dirpath + '/' + trackname\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 512, 128, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAS.SR, PARAS.N_FFT, PARAS.N_MEL, PARAS.SAMPLE_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mix': '../DSD100/Mixtures/Dev/056 - Arise - Run Run Run/mixture.wav',\n",
       "  'vocals': '../DSD100/Sources/Dev/056 - Arise - Run Run Run/vocals.wav',\n",
       "  'drums': '../DSD100/Sources/Dev/056 - Arise - Run Run Run/drums.wav',\n",
       "  'other': '../DSD100/Sources/Dev/056 - Arise - Run Run Run/other.wav',\n",
       "  'bass': '../DSD100/Sources/Dev/056 - Arise - Run Run Run/bass.wav'},\n",
       " 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = dev_file_paths['056']\n",
    "test_path, len(dev_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Points\n",
    "- Do not use the origin mix track, using the sum of vocal and background tracks and return a new mixed track, because the old track is not ensured the normalization\n",
    "### Remove vocal silence part ( slience is useless for model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_silence(vocal, target_track):\n",
    "    \"\"\"\n",
    "    This function remove slience part\n",
    "    notice it's not an in place dealer\n",
    "    \"\"\"\n",
    "    remove_list = list()\n",
    "    for i, point in enumerate(vocal):\n",
    "        if 10**-4 > abs(point): # be careful of the silence part shreshold\n",
    "            remove_list.append(i)\n",
    "    vocal_out = np.delete(vocal, remove_list)\n",
    "    target_track_out = np.delete(target_track, remove_list)\n",
    "    return vocal_out, target_track_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the mix/target signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sound_tracks_extractor(file_path):\n",
    "    \"\"\"\n",
    "    Take in a file path dictionary, return:\n",
    "    (Normalized track)\n",
    "    vocal track as target\n",
    "    mixed track as input\n",
    "    \"\"\"\n",
    "    signals = dict()\n",
    "    for key in file_path:\n",
    "        if key == 'mix':\n",
    "            continue\n",
    "        signals[key], _ = librosa.load(file_path.get(key), sr = PARAS.SR)\n",
    "        signals[key] = librosa.util.normalize(signals.get(key))\n",
    "        \n",
    "    vocal_track = signals.get('vocals')\n",
    "    return_vocal, _ = remove_silence(vocal_track, vocal_track)\n",
    "    background_track = np.zeros(len(return_vocal))\n",
    "    background_track_list = list()\n",
    "    \n",
    "    for key in signals:\n",
    "        if 'vocals' == key:\n",
    "            continue\n",
    "        _, signals[key] = remove_silence(vocal_track, signals.get(key))\n",
    "        background_track = signals.get(key) if not len(background_track) else background_track + signals.get(key)\n",
    "        background_track_list.append(background_track)\n",
    "    \n",
    "    mix_track_list = [return_vocal + bg for bg in background_track_list] # this is for increase the dataset size\n",
    "    \n",
    "    return return_vocal, background_track_list, mix_track_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate chunks Spectrogram\n",
    "#### Use MelConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =  sound_tracks_extractor(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create mel_spectrogram (150 * 150 frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_feature_extractor(signal, mel_converter=mel_converter):\n",
    "    \"\"\"\n",
    "    Takes in new signals and create mel chunks \n",
    "    \"\"\"\n",
    "    S = mel_converter.signal_to_melspec(signal)\n",
    "    if not S.shape[0] % PARAS.N_MEL == 0:\n",
    "        S = S[:-1 * (S.shape[0] % PARAS.N_MEL)] # divide the mel spectrogram\n",
    "        \n",
    "    chunk_num = int(S.shape[0] / PARAS.N_MEL)\n",
    "    mel_chunks = np.split(S, chunk_num) # create 150 * 150 data frames\n",
    "    return mel_chunks, chunk_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sound_tracks_dealer(tracks_mix, mel_converter=mel_converter):\n",
    "    vocal, background_track_list, mix_track_list = tracks_mix\n",
    "    b_chunks, m_chunks, v_chunks = list(), list(), list()\n",
    "    \n",
    "    vocal_chunks, cn = frame_feature_extractor(vocal)\n",
    "    for i in range(len(mix_track_list)):\n",
    "        current_bg, _ = frame_feature_extractor(background_track_list[i])\n",
    "        current_mix, _ = frame_feature_extractor(mix_track_list[i])\n",
    "        b_chunks = b_chunks + current_bg\n",
    "        m_chunks = m_chunks + current_mix\n",
    "        v_chunks = v_chunks + vocal_chunks\n",
    "    return v_chunks, b_chunks, m_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = dict(list(dev_file_paths.items())\n",
    "                  + list(test_file_paths.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "Load data in to small databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start loading data...\n",
      "=>$055[51.06s|LEFT:99|CHUNK:420] \n",
      "=>$084[81.17s|LEFT:98|CHUNK:912] \n",
      "=>$077[63.78s|LEFT:97|CHUNK:1494] \n",
      "=>$058[71.01s|LEFT:96|CHUNK:1938] \n",
      "=>$062[72.0s|LEFT:95|CHUNK:2505] \n",
      "=>$092[91.24s|LEFT:94|CHUNK:3333] \n",
      "=>$095[122.66s|LEFT:93|CHUNK:4143] \n",
      "=>$072[70.97s|LEFT:92|CHUNK:4686] \n",
      "=>$063[52.61s|LEFT:91|CHUNK:4818] \n",
      "=>$087[89.08s|LEFT:90|CHUNK:5082] \n",
      "=>$073[74.36s|LEFT:89|CHUNK:5760] \n",
      "=>$060[78.89s|LEFT:88|CHUNK:6318] \n",
      "=>$067[119.03s|LEFT:87|CHUNK:7083] \n",
      "=>$081[79.1s|LEFT:86|CHUNK:7416] \n",
      "=>$083[68.82s|LEFT:84|CHUNK:8631] \n",
      "=>$097[65.99s|LEFT:83|CHUNK:9213] \n",
      "=>$068[55.8s|LEFT:82|CHUNK:9687] \n",
      "=>$065[56.93s|LEFT:81|CHUNK:10101] \n",
      "=>$090[92.52s|LEFT:80|CHUNK:11055] \n",
      "=>$088[86.6s|LEFT:79|CHUNK:11835] \n",
      "=>$082[62.66s|LEFT:78|CHUNK:12201] \n",
      "=>$093[67.44s|LEFT:77|CHUNK:12609] \n",
      "=>$074[74.66s|LEFT:76|CHUNK:13164] \n",
      "=>$057[94.86s|LEFT:75|CHUNK:13788] \n",
      "=>$052[59.31s|LEFT:74|CHUNK:14355] \n",
      "=>$091[90.62s|LEFT:73|CHUNK:15024] \n",
      "=>$064[51.89s|LEFT:72|CHUNK:15492] \n",
      "=>$080[68.91s|LEFT:71|CHUNK:15861] \n",
      "=>$098[68.24s|LEFT:70|CHUNK:16428] \n",
      "=>$053[57.38s|LEFT:69|CHUNK:16926] \n",
      "=>$079[78.56s|LEFT:68|CHUNK:17631] \n",
      "=>$071[70.73s|LEFT:67|CHUNK:18060] \n",
      "=>$066[87.03s|LEFT:66|CHUNK:18444] \n",
      "=>$099[70.56s|LEFT:65|CHUNK:18816] \n",
      "=>$096[67.77s|LEFT:64|CHUNK:19386] \n",
      "=>$076[79.52s|LEFT:63|CHUNK:20142] \n",
      "=>$059[111.86s|LEFT:62|CHUNK:20736] \n",
      "=>$100[77.96s|LEFT:61|CHUNK:21342] \n",
      "=>$078[53.67s|LEFT:60|CHUNK:21816] \n",
      "=>$054[51.0s|LEFT:59|CHUNK:22287] \n",
      "=>$085[69.97s|LEFT:58|CHUNK:22932] \n",
      "=>$056[60.57s|LEFT:57|CHUNK:23487] \n",
      "=>$069[45.6s|LEFT:56|CHUNK:23703] \n",
      "=>$094[69.52s|LEFT:55|CHUNK:24033] \n",
      "=>$070[60.91s|LEFT:54|CHUNK:24540] \n",
      "=>$089[67.89s|LEFT:53|CHUNK:25167] \n",
      "=>$075[65.09s|LEFT:52|CHUNK:25680] \n",
      "=>$061[85.17s|LEFT:51|CHUNK:26322] \n",
      "=>$051[59.16s|LEFT:50|CHUNK:26772] \n",
      "=>$023[52.99s|LEFT:49|CHUNK:27123] \n",
      "=>$004[55.35s|LEFT:48|CHUNK:27669] \n",
      "=>$046[56.6s|LEFT:47|CHUNK:28161] \n",
      "=>$011[79.94s|LEFT:46|CHUNK:28584] \n",
      "=>$003[47.61s|LEFT:45|CHUNK:29052] \n",
      "=>$014[47.67s|LEFT:44|CHUNK:29481] \n",
      "=>$032[60.7s|LEFT:43|CHUNK:29949] \n",
      "=>$033[88.26s|LEFT:42|CHUNK:30432] \n",
      "=>$001[67.16s|LEFT:41|CHUNK:30948] \n",
      "=>$019[58.36s|LEFT:40|CHUNK:31407] \n",
      "=>$039[86.62s|LEFT:39|CHUNK:32070] \n",
      "=>$031[62.29s|LEFT:38|CHUNK:32409] \n",
      "=>$002[48.29s|LEFT:37|CHUNK:32814] \n",
      "=>$024[72.63s|LEFT:36|CHUNK:33378] \n",
      "=>$009[61.73s|LEFT:35|CHUNK:33846] \n",
      "=>$025[52.5s|LEFT:34|CHUNK:34215] \n",
      "=>$036[108.24s|LEFT:33|CHUNK:34377] \n",
      "=>$013[102.6s|LEFT:32|CHUNK:35289] \n",
      "=>$016[76.56s|LEFT:31|CHUNK:35628] \n",
      "=>$042[56.02s|LEFT:30|CHUNK:36057] \n",
      "=>$049[48.3s|LEFT:29|CHUNK:36432] \n",
      "=>$026[80.54s|LEFT:28|CHUNK:36777] \n",
      "=>$006[75.77s|LEFT:27|CHUNK:37377] \n",
      "=>$041[68.01s|LEFT:26|CHUNK:37797] \n",
      "=>$043[71.46s|LEFT:25|CHUNK:38496] \n",
      "=>$037[73.65s|LEFT:24|CHUNK:39201] \n",
      "=>$034[69.89s|LEFT:23|CHUNK:39606] \n",
      "=>$028[67.41s|LEFT:22|CHUNK:40062] \n",
      "=>$045[115.78s|LEFT:21|CHUNK:40665] \n",
      "=>$044[50.08s|LEFT:20|CHUNK:41025] \n",
      "=>$027[74.53s|LEFT:19|CHUNK:41703] \n",
      "=>$018[39.08s|LEFT:18|CHUNK:41934] \n",
      "=>$008[64.71s|LEFT:17|CHUNK:42333] \n",
      "=>$022[82.48s|LEFT:16|CHUNK:42885] \n",
      "=>$040[75.4s|LEFT:15|CHUNK:43326] \n",
      "=>$007[62.63s|LEFT:14|CHUNK:43734] \n",
      "=>$048[58.95s|LEFT:13|CHUNK:44076] \n",
      "=>$015[54.22s|LEFT:12|CHUNK:44556] \n",
      "=>$010[74.39s|LEFT:11|CHUNK:45150] \n",
      "=>$012[65.09s|LEFT:10|CHUNK:45666] \n",
      "=>$030[71.97s|LEFT:8|CHUNK:46386] \n",
      "=>$050[66.72s|LEFT:7|CHUNK:46944] \n",
      "=>$029[97.06s|LEFT:5|CHUNK:48045] \n",
      "=>$035[51.14s|LEFT:4|CHUNK:48492] \n",
      "=>$020[69.11s|LEFT:3|CHUNK:49017] \n",
      "=>$017[89.14s|LEFT:2|CHUNK:49338] \n",
      "=>$038[72.29s|LEFT:1|CHUNK:49716] \n",
      "=>$047[59.92s|LEFT:0|CHUNK:50151] \n",
      "******END*******\n",
      "TOTAL CHUNK: 50151\n",
      "TOTAL TIME: 118.12min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"start loading data...\")\n",
    "file_count = 100\n",
    "chunk_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for key, file_dict in file_paths.items():\n",
    "    ss_time = time.time()\n",
    "    count = 0\n",
    "    \n",
    "    '''\n",
    "    vocal_signal, bg_signal, mix_signal = sound_tracks_extractor(file_dict)\n",
    "    vocal_chunks, cn = frame_feature_extractor(vocal_signal)\n",
    "    mix_chunks, _ = frame_feature_extractor(mix_signal)\n",
    "    bg_chunks, _ = frame_feature_extractor(bg_signal)\n",
    "    '''\n",
    "    \n",
    "    mix_tracks = sound_tracks_extractor(file_dict)\n",
    "    vocal_chunks, bg_chunks, mix_chunks = sound_tracks_dealer(mix_tracks)\n",
    "    cn = len(vocal_chunks)\n",
    "    \n",
    "    c_setpath = PARAS.DATASET_PATH + '{0}.h5'.format(key)\n",
    "    c_dataset = h5py.File(c_setpath, 'a')\n",
    "    \n",
    "    c_dataset.create_dataset('mix', \n",
    "                       shape=(cn, PARAS.N_MEL, PARAS.N_MEL),   \n",
    "                       dtype=np.float32)\n",
    "    \n",
    "    c_dataset.create_dataset('bg', \n",
    "                       shape=(cn, PARAS.N_MEL, PARAS.N_MEL), \n",
    "                       dtype=np.float32)\n",
    "\n",
    "    c_dataset.create_dataset('vocal', \n",
    "                           shape=(cn, PARAS.N_MEL, PARAS.N_MEL), \n",
    "                           dtype=np.float32)\n",
    "    \n",
    "    for idx in range(cn):\n",
    "        c_dataset['vocal'][count] = vocal_chunks[idx]\n",
    "        c_dataset['mix'][count] = mix_chunks[idx]\n",
    "        c_dataset['bg'][count] = bg_chunks[idx]\n",
    "        count += 1\n",
    "        chunk_count += 1\n",
    "    \n",
    "    file_count -= 1\n",
    "    epoch_s = round(time.time() - ss_time, 2)\n",
    "    print(\"=>${0}[{1}s|LEFT:{2}|CHUNK:{3}] \".format(key, epoch_s, file_count, chunk_count))\n",
    "    c_dataset.close()\n",
    "print('******END*******')\n",
    "print(\"TOTAL CHUNK: {0}\".format(chunk_count))\n",
    "print(\"TOTAL TIME: {0}min\".format(round(((time.time()-start_time) / 60), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets\n",
    "### Create all in one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_setpath = PARAS.DATASET_PATH + 'all_enhanced.h5'\n",
    "all_dataset = h5py.File(all_setpath, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"bg\": shape (50151, 128, 128), type \"<f4\">"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_dataset.create_dataset('mix', \n",
    "                       shape=(chunk_count, PARAS.N_MEL, PARAS.N_MEL), \n",
    "                       dtype=np.float32)\n",
    "\n",
    "all_dataset.create_dataset('vocal', \n",
    "                       shape=(chunk_count, PARAS.N_MEL, PARAS.N_MEL), \n",
    "                       dtype=np.float32)\n",
    "\n",
    "all_dataset.create_dataset('bg', \n",
    "                       shape=(chunk_count, PARAS.N_MEL, PARAS.N_MEL), \n",
    "                       dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for (dirpath, dirnames, filenames) in os.walk(PARAS.DATASET_PATH):\n",
    "    if filenames:\n",
    "        for set_name in filenames:\n",
    "            if 'h5' not in set_name or 'all' in set_name:\n",
    "                continue\n",
    "            set_path = PARAS.DATASET_PATH + set_name\n",
    "            tmp_dataset = h5py.File(set_path, 'r')\n",
    "            tmp_count = tmp_dataset['vocal'].shape[0]\n",
    "            for i in range(tmp_count):\n",
    "                all_dataset['mix'][count] = tmp_dataset['mix'][i]\n",
    "                all_dataset['vocal'][count] = tmp_dataset['vocal'][i]\n",
    "                all_dataset['bg'][count] = tmp_dataset['bg'][i]\n",
    "                count += 1\n",
    "            tmp_dataset.close()\n",
    "all_dataset.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "all_setpath = PARAS.DATASET_PATH + 'all_enhanced.h5'\n",
    "all_dataset = h5py.File(all_setpath, 'r')\n",
    "\n",
    "train_set = PARAS.DATASET_PATH+'train_enhanced.h5'\n",
    "valid_set = PARAS.DATASET_PATH+'valid_enhanced.h5'\n",
    "test_set = PARAS.DATASET_PATH+'test_enhanced.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40120 5015 5016\n"
     ]
    }
   ],
   "source": [
    "train_file = int(chunk_count * 0.8)\n",
    "valid_file = int(chunk_count * 0.1)\n",
    "test_file = chunk_count - train_file - valid_file\n",
    "print(train_file, valid_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40120, 5015, 5016]\n"
     ]
    }
   ],
   "source": [
    "files = [int(a) for a in [train_file, valid_file, test_file]]\n",
    "sets = [train_set, valid_set, test_set]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [i for i in range(chunk_count)]\n",
    "random.seed(516)\n",
    "random.shuffle(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = idx[:files[0]]\n",
    "valid_idx = idx[files[0]: files[0]+files[1]]\n",
    "test_idx = idx[-files[2]:]\n",
    "indices = [train_idx, valid_idx, test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=>100=>200=>300=>400=>500=>600=>700=>800=>900=>1000=>1100=>1200=>1300=>1400=>1500=>1600=>1700=>1800=>1900=>2000=>2100=>2200=>2300=>2400=>2500=>2600=>2700=>2800=>2900=>3000=>3100=>3200=>3300=>3400=>3500=>3600=>3700=>3800=>3900=>4000=>4100=>4200=>4300=>4400=>4500=>4600=>4700=>4800=>4900=>5000=>5100=>5200=>5300=>5400=>5500=>5600=>5700=>5800=>5900=>6000=>6100=>6200=>6300=>6400=>6500=>6600=>6700=>6800=>6900=>7000=>7100=>7200=>7300=>7400=>7500=>7600=>7700=>7800=>7900=>8000=>8100=>8200=>8300=>8400=>8500=>8600=>8700=>8800=>8900=>9000=>9100=>9200=>9300=>9400=>9500=>9600=>9700=>9800=>9900=>10000=>10100=>10200=>10300=>10400=>10500=>10600=>10700=>10800=>10900=>11000=>11100=>11200=>11300=>11400=>11500=>11600=>11700=>11800=>11900=>12000=>12100=>12200=>12300=>12400=>12500=>12600=>12700=>12800=>12900=>13000=>13100=>13200=>13300=>13400=>13500=>13600=>13700=>13800=>13900=>14000=>14100=>14200=>14300=>14400=>14500=>14600=>14700=>14800=>14900=>15000=>15100=>15200=>15300=>15400=>15500=>15600=>15700=>15800=>15900=>16000=>16100=>16200=>16300=>16400=>16500=>16600=>16700=>16800=>16900=>17000=>17100=>17200=>17300=>17400=>17500=>17600=>17700=>17800=>17900=>18000=>18100=>18200=>18300=>18400=>18500=>18600=>18700=>18800=>18900=>19000=>19100=>19200=>19300=>19400=>19500=>19600=>19700=>19800=>19900=>20000=>20100=>20200=>20300=>20400=>20500=>20600=>20700=>20800=>20900=>21000=>21100=>21200=>21300=>21400=>21500=>21600=>21700=>21800=>21900=>22000=>22100=>22200=>22300=>22400=>22500=>22600=>22700=>22800=>22900=>23000=>23100=>23200=>23300=>23400=>23500=>23600=>23700=>23800=>23900=>24000=>24100=>24200=>24300=>24400=>24500=>24600=>24700=>24800=>24900=>25000=>25100=>25200=>25300=>25400=>25500=>25600=>25700=>25800=>25900=>26000=>26100=>26200=>26300=>26400=>26500=>26600=>26700=>26800=>26900=>27000=>27100=>27200=>27300=>27400=>27500=>27600=>27700=>27800=>27900=>28000=>28100=>28200=>28300=>28400=>28500=>28600=>28700=>28800=>28900=>29000=>29100=>29200=>29300=>29400=>29500=>29600=>29700=>29800=>29900=>30000=>30100=>30200=>30300=>30400=>30500=>30600=>30700=>30800=>30900=>31000=>31100=>31200=>31300=>31400=>31500=>31600=>31700=>31800=>31900=>32000=>32100=>32200=>32300=>32400=>32500=>32600=>32700=>32800=>32900=>33000=>33100=>33200=>33300=>33400=>33500=>33600=>33700=>33800=>33900=>34000=>34100=>34200=>34300=>34400=>34500=>34600=>34700=>34800=>34900=>35000=>35100=>35200=>35300=>35400=>35500=>35600=>35700=>35800=>35900=>36000=>36100=>36200=>36300=>36400=>36500=>36600=>36700=>36800=>36900=>37000=>37100=>37200=>37300=>37400=>37500=>37600=>37700=>37800=>37900=>38000=>38100=>38200=>38300=>38400=>38500=>38600=>38700=>38800=>38900=>39000=>39100=>39200=>39300=>39400=>39500=>39600=>39700=>39800=>39900=>40000=>40100\n",
      "Create Separate Datasets ../Dataset/train_enhanced.h5\n",
      "=>100=>200=>300=>400=>500=>600=>700=>800=>900=>1000=>1100=>1200=>1300=>1400=>1500=>1600=>1700=>1800=>1900=>2000=>2100=>2200=>2300=>2400=>2500=>2600=>2700=>2800=>2900=>3000=>3100=>3200=>3300=>3400=>3500=>3600=>3700=>3800=>3900=>4000=>4100=>4200=>4300=>4400=>4500=>4600=>4700=>4800=>4900=>5000\n",
      "Create Separate Datasets ../Dataset/valid_enhanced.h5\n",
      "=>100=>200=>300=>400=>500=>600=>700=>800=>900=>1000=>1100=>1200=>1300=>1400=>1500=>1600=>1700=>1800=>1900=>2000=>2100=>2200=>2300=>2400=>2500=>2600=>2700=>2800=>2900=>3000=>3100=>3200=>3300=>3400=>3500=>3600=>3700=>3800=>3900=>4000=>4100=>4200=>4300=>4400=>4500=>4600=>4700=>4800=>4900=>5000\n",
      "Create Separate Datasets ../Dataset/test_enhanced.h5\n"
     ]
    }
   ],
   "source": [
    "for i, dset in enumerate(sets):\n",
    "    s_set = h5py.File(dset, 'a')\n",
    "    indice = indices[i]\n",
    "    file_num = files[i]\n",
    "    \n",
    "    s_set.create_dataset('vocal', shape=(file_num, PARAS.N_MEL, PARAS.N_MEL), dtype=np.float32)\n",
    "    s_set.create_dataset('mix', shape=(file_num, PARAS.N_MEL, PARAS.N_MEL), dtype=np.float32)\n",
    "    s_set.create_dataset('bg', shape=(file_num, PARAS.N_MEL, PARAS.N_MEL), dtype=np.float32)\n",
    "    \n",
    "    count = 0\n",
    "    for i in indice:\n",
    "        s_set['vocal'][count] = all_dataset['vocal'][i]\n",
    "        s_set['mix'][count] = all_dataset['mix'][i]\n",
    "        s_set['bg'][count] = all_dataset['bg'][i]\n",
    "        count += 1\n",
    "        \n",
    "        if count % 100 == 0:\n",
    "            print('=>{0}'.format(count), end=\"\")\n",
    "    \n",
    "    s_set.close()\n",
    "    print()  \n",
    "    print('Create Separate Datasets {0}'.format(dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
